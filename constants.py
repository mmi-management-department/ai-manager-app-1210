"""
このファイルは、固定の文字列や数値などのデータを変数として一括管理するファイルです。
"""

############################################################
# ライブラリの読み込み
############################################################
from langchain_community.document_loaders import PyMuPDFLoader, Docx2txtLoader, TextLoader
from langchain_community.document_loaders.csv_loader import CSVLoader


############################################################
# 共通変数の定義
############################################################

# ==========================================
# 画面表示系
# ==========================================
APP_NAME = "社内情報検索AI<br>- 株式会社エムエムインターナショナル<br>AI管理部長"
ANSWER_MODE_1 = "社内文書検索"
ANSWER_MODE_2 = "管理部への問い合わせ"  # Updated: 2025-12-14
CHAT_INPUT_HELPER_TEXT = "こちらからメッセージを送信してください。"
DOC_SOURCE_ICON = ":material/description: "
LINK_SOURCE_ICON = ":material/link: "
WARNING_ICON = ":material/warning:"
ERROR_ICON = ":material/error:"
SPINNER_TEXT = "回答生成中..."


# ==========================================
# ログ出力系
# ==========================================
LOG_DIR_PATH = "./logs"
LOGGER_NAME = "ApplicationLog"
LOG_FILE = "application.log"
APP_BOOT_MESSAGE = "アプリが起動されました。"


# ==========================================
# LLM設定系
# ==========================================
# Google Gemini モデル（無料版: gemini-1.5-flash, 有料版: gemini-1.5-pro）
MODEL = "gemini-1.5-flash"
# OpenAI モデル（gpt-4o-mini: 高速・低コスト, gpt-4o: 高性能）
MODEL_OPENAI = "gpt-4o-mini"
# Google Gemini 埋め込みモデル
EMBEDDING_MODEL = "models/embedding-001"
# OpenAI 埋め込みモデル
EMBEDDING_MODEL_OPENAI = "text-embedding-3-small"
TEMPERATURE = 0.5


# ==========================================
# RAG参照用のデータソース系
# ==========================================
RAG_TOP_FOLDER_PATH = "./data"
# 統合済みのdataフォルダのみを検索対象にする
RAG_FOLDER_PATHS = ["./data"]
SUPPORTED_EXTENSIONS = {
    ".pdf": PyMuPDFLoader,
    ".docx": Docx2txtLoader,
    ".csv": lambda path: CSVLoader(path, encoding="utf-8"),
    ".txt": lambda path: TextLoader(path, encoding="utf-8"),
    ".md": lambda path: TextLoader(path, encoding="utf-8"),
    ".xlsx": None,  # Custom loader in initialize.py
    ".xls": None  # Custom loader in initialize.py
}
WEB_URL_LOAD_TARGETS = [
    "https://generative-ai.web-camp.io/"
]

# ==========================================
# RAG設定（検索・チャンク分割）
# ==========================================
# ベクターストアから取り出すドキュメント数（増加：より多くの関連情報を取得）
RETRIEVER_SEARCH_K = 10
# チャンク分割時のチャンクサイズ（増加：より多くの文脈を保持）
CHUNK_SIZE = 800
# チャンク分割時のオーバーラップサイズ（増加：文脈の連続性を向上）
CHUNK_OVERLAP = 100


# ==========================================
# プロンプトテンプレート
# ==========================================
SYSTEM_PROMPT_CREATE_INDEPENDENT_TEXT = """会話履歴と最新の入力をもとに、会話履歴なしでも理解できる独立した入力テキストを生成してください。

【重要な指示】
- 「それについて」「もっと詳しく」「これについて」などの指示代名詞や副詞がある場合は、会話履歴から具体的な対象を特定してください。
- 例：「JINNYについて教えて」→「JINNYについてもっと詳しく教えて」の場合、「JINNYについて詳細な情報を教えてください」に変換してください。
- 口語的な表現を、検索に適した明確な質問文に変換してください。
- 会話履歴で言及されたキーワード（製品名、サービス名、人名など）を必ず含めてください。
"""

SYSTEM_PROMPT_DOC_SEARCH = """
    あなたは社内の文書検索アシスタントです。
    以下の条件に基づき、ユーザー入力に対して回答してください。

    【重要な制約】
    - 必ず以下の文脈に記載されている情報のみを使用してください。
    - 推測、憶測、一般的な知識での補足は一切行わないでください。
    - 文脈に明確に記載されていない情報については回答しないでください。

    【回答の基本方針】
    1. 文脈に関連する情報が少しでもある場合は、積極的に回答してください。
    2. 文脈から得られる情報をできる限り詳細に、網羅的に説明してください。
    3. 複数の文脈が提供されている場合、それらを統合して包括的な回答を作成してください。
    4. 文脈に質問と関連するキーワード（製品名、サービス名、人名、部署名など）が含まれている場合、それに関する情報を全て抽出して回答に含めてください。

    【回答形式】
    1. できる限り詳細に、マークダウン記法を使って回答してください。
    2. マークダウン記法で回答する際にhタグの見出しを使う場合、最も大きい見出しをh3としてください。
    3. 箇条書きや表を活用して、情報を整理して提示してください。
    4. 複雑な質問の場合、各項目についてそれぞれ文脈に基づいて回答してください。
    5. どの文書から情報を得たかが分かるように、情報の出典を明示してください。

    【情報が不足している場合】
    - 文脈に質問と関連する情報が全く含まれていない場合のみ、「該当資料なし」と回答してください。
    - 部分的に情報がある場合は、得られる情報だけでも回答し、「さらに詳しい情報については文書内に記載がありません」と補足してください。

    【文脈】
    {context}
"""

SYSTEM_PROMPT_INQUIRY = """
    あなたは社内情報特化型のアシスタントです。
    以下の条件に基づき、ユーザー入力に対して回答してください。

    【重要な制約】
    - 必ず以下の文脈に記載されている情報のみを使用してください。
    - 推測、憶測、一般的な知識での補足は一切行わないでください。
    - 文脈に明確に記載されていない情報については回答しないでください。

    【回答の基本方針】
    1. 文脈に関連する情報が少しでもある場合は、積極的に回答してください。
    2. 文脈から得られる情報をできる限り詳細に、網羅的に説明してください。
    3. 複数の文脈が提供されている場合、それらを統合して包括的な回答を作成してください。
    4. 文脈に質問と関連するキーワード（製品名、サービス名、用語など）が含まれている場合、それに関する情報を全て抽出して回答に含めてください。

    【回答形式】
    1. できる限り詳細に、マークダウン記法を使って回答してください。
    2. マークダウン記法で回答する際にhタグの見出しを使う場合、最も大きい見出しをh3としてください。
    3. 箇条書きや表を活用して、情報を整理して提示してください。
    4. 複雑な質問の場合、各項目についてそれぞれ文脈に基づいて回答してください。
    
    【情報が不足している場合】
    - 文脈に質問と関連する情報が全く含まれていない場合のみ、「回答に必要な情報が見つかりませんでした。」と回答してください。
    - 部分的に情報がある場合は、得られる情報だけでも回答し、「さらに詳しい情報については文書内に記載がありません」と補足してください。
    
    【重要：賃金・給与・報酬に関する質問への対応】
    質問が賃金、給与、報酬、給与体系、賃金形態などに関する場合：
    - 文脈に「賃金規程」の情報がある場合は、必ず一般社員（正社員）の賃金情報を含めて回答してください。
    - 「執行役員報酬規程」の情報だけでなく、「賃金規程」に基づく一般社員の情報も必ず記載してください。
    - 正社員、契約社員、パート社員など、複数の雇用形態の情報がある場合は、それぞれについて説明してください。
    - グレード制度、基本給、各種手当など、賃金体系の詳細も含めて説明してください。

    【文脈】
    {context}
"""


# ==========================================
# LLMレスポンスの一致判定用
# ==========================================
INQUIRY_NO_MATCH_ANSWER = "回答に必要な情報が見つかりませんでした。"
NO_DOC_MATCH_ANSWER = "該当資料なし"


# ==========================================
# エラー・警告メッセージ
# ==========================================
COMMON_ERROR_MESSAGE = "このエラーが繰り返し発生する場合は、管理者にお問い合わせください。"
INITIALIZE_ERROR_MESSAGE = "初期化処理に失敗しました。"
NO_DOC_MATCH_MESSAGE = """
    入力内容と関連する社内文書が見つかりませんでした。\n
    入力内容を変更してください。
"""
CONVERSATION_LOG_ERROR_MESSAGE = "過去の会話履歴の表示に失敗しました。"
GET_LLM_RESPONSE_ERROR_MESSAGE = "回答生成に失敗しました。"
DISP_ANSWER_ERROR_MESSAGE = "回答表示に失敗しました。"