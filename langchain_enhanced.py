"""
LangChainå¼·åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
é«˜åº¦ãªLangChainæ©Ÿèƒ½ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

æ©Ÿèƒ½ï¼š
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™
- å…¥åŠ›æ¤œè¨¼
- ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- è©³ç´°ãªãƒ­ã‚°
"""

import time
import hashlib
import json
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta

import streamlit as st
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.messages import BaseMessage
from langchain_core.outputs import LLMResult


class StreamHandler(BaseCallbackHandler):
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    LLMã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã—ã¾ã™
    """
    
    def __init__(self, container):
        self.container = container
        self.text = ""
        
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ãŒç”Ÿæˆã•ã‚ŒãŸã¨ãã«å‘¼ã°ã‚Œã‚‹"""
        self.text += token
        self.container.markdown(self.text)


class RateLimiter:
    """
    ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å®Ÿè£…ã™ã‚‹ã‚¯ãƒ©ã‚¹
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå›æ•°ã‚’åˆ¶é™ã—ã¾ã™
    """
    
    def __init__(self, max_requests: int = 10, time_window: int = 60):
        """
        Args:
            max_requests: æ™‚é–“æ å†…ã®æœ€å¤§ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
            time_window: æ™‚é–“æ ï¼ˆç§’ï¼‰
        """
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = {}
    
    def is_allowed(self, user_id: str = "default") -> tuple[bool, int]:
        """
        ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒè¨±å¯ã•ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            
        Returns:
            tuple: (è¨±å¯ã•ã‚Œã‚‹ã‹, æ®‹ã‚Šãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°)
        """
        current_time = time.time()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆå±¥æ­´ã‚’å–å¾—
        if user_id not in self.requests:
            self.requests[user_id] = []
        
        # æ™‚é–“æ å¤–ã®å¤ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
        self.requests[user_id] = [
            req_time for req_time in self.requests[user_id]
            if current_time - req_time < self.time_window
        ]
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’ãƒã‚§ãƒƒã‚¯
        if len(self.requests[user_id]) < self.max_requests:
            self.requests[user_id].append(current_time)
            remaining = self.max_requests - len(self.requests[user_id])
            return True, remaining
        
        return False, 0


class QueryCache:
    """
    ã‚¯ã‚¨ãƒªã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½
    åŒã˜è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦åŠ¹ç‡åŒ–ã—ã¾ã™
    """
    
    def __init__(self, cache_file: str = "logs/query_cache.json", max_size: int = 100):
        """
        Args:
            cache_file: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            max_size: æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
        """
        self.cache_file = Path(cache_file)
        self.cache_file.parent.mkdir(exist_ok=True)
        self.max_size = max_size
        self.cache = self._load_cache()
    
    def _load_cache(self) -> dict:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                return {}
        return {}
    
    def _save_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # æœ€å¤§ã‚µã‚¤ã‚ºã‚’è¶…ãˆãŸã‚‰å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
            if len(self.cache) > self.max_size:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆã—ã¦å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
                sorted_items = sorted(
                    self.cache.items(),
                    key=lambda x: x[1].get('timestamp', 0)
                )
                self.cache = dict(sorted_items[-self.max_size:])
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _get_cache_key(self, query: str) -> str:
        """ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        return hashlib.md5(query.encode()).hexdigest()
    
    def get(self, query: str, max_age: int = 3600) -> Optional[str]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å›ç­”ã‚’å–å¾—
        
        Args:
            query: è³ªå•
            max_age: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ€å¤§æœ‰åŠ¹æœŸé–“ï¼ˆç§’ï¼‰
            
        Returns:
            ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå›ç­”ã€ã¾ãŸã¯None
        """
        cache_key = self._get_cache_key(query)
        
        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            timestamp = cached_item.get('timestamp', 0)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹æœŸé™å†…ã‹ãƒã‚§ãƒƒã‚¯
            if time.time() - timestamp < max_age:
                return cached_item.get('answer')
        
        return None
    
    def set(self, query: str, answer: str):
        """
        å›ç­”ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        
        Args:
            query: è³ªå•
            answer: å›ç­”
        """
        cache_key = self._get_cache_key(query)
        
        self.cache[cache_key] = {
            'query': query,
            'answer': answer,
            'timestamp': time.time()
        }
        
        self._save_cache()
    
    def clear(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self.cache = {}
        self._save_cache()


class InputValidator:
    """
    å…¥åŠ›æ¤œè¨¼ã‚¯ãƒ©ã‚¹
    è³ªå•ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
    """
    
    @staticmethod
    def validate(query: str, max_length: int = 1000) -> tuple[bool, str]:
        """
        å…¥åŠ›ã‚’æ¤œè¨¼
        
        Args:
            query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            max_length: æœ€å¤§æ–‡å­—æ•°
            
        Returns:
            tuple: (æœ‰åŠ¹ã‹ã©ã†ã‹, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
        """
        # ç©ºæ–‡å­—ãƒã‚§ãƒƒã‚¯
        if not query or not query.strip():
            return False, "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        
        # é•·ã•ãƒã‚§ãƒƒã‚¯
        if len(query) > max_length:
            return False, f"è³ªå•ãŒé•·ã™ãã¾ã™ï¼ˆæœ€å¤§{max_length}æ–‡å­—ï¼‰ã€‚"
        
        # æœ€å°æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
        if len(query.strip()) < 2:
            return False, "è³ªå•ãŒçŸ­ã™ãã¾ã™ã€‚ã‚‚ã†å°‘ã—è©³ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        
        return True, ""


class LangChainLogger:
    """
    LangChainå°‚ç”¨ã®ãƒ­ã‚¬ãƒ¼
    è©³ç´°ãªãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã¾ã™
    """
    
    def __init__(self, log_file: str = "logs/langchain_log.json"):
        self.log_file = Path(log_file)
        self.log_file.parent.mkdir(exist_ok=True)
    
    def log_query(
        self,
        query: str,
        answer: str,
        sources: List[str],
        elapsed_time: float,
        success: bool = True,
        error: str = None
    ):
        """
        ã‚¯ã‚¨ãƒªã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        
        Args:
            query: è³ªå•
            answer: å›ç­”
            sources: å‚ç…§å…ƒã®ãƒªã‚¹ãƒˆ
            elapsed_time: å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰
            success: æˆåŠŸã—ãŸã‹
            error: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚ã‚Œã°ï¼‰
        """
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "answer": answer if success else None,
            "sources": sources,
            "elapsed_time": elapsed_time,
            "success": success,
            "error": error
        }
        
        try:
            # æ—¢å­˜ã®ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚€
            if self.log_file.exists():
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            else:
                logs = []
            
            # æ–°ã—ã„ãƒ­ã‚°ã‚’è¿½åŠ 
            logs.append(log_entry)
            
            # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
            logs = logs[-100:]
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_logs(self, limit: int = 50) -> list:
        """
        ãƒ­ã‚°ã‚’å–å¾—
        
        Args:
            limit: å–å¾—ã™ã‚‹ä»¶æ•°
            
        Returns:
            ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
        """
        try:
            if self.log_file.exists():
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
                return logs[-limit:]
        except Exception:
            return []
        
        return []


class ConversationManager:
    """
    ä¼šè©±å±¥æ­´ç®¡ç†ã‚¯ãƒ©ã‚¹
    ä¼šè©±å±¥æ­´ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ãƒ»ç®¡ç†ã‚’è¡Œã„ã¾ã™
    """
    
    def __init__(self, max_history: int = 10):
        """
        Args:
            max_history: ä¿æŒã™ã‚‹æœ€å¤§ä¼šè©±æ•°
        """
        self.max_history = max_history
    
    def trim_history(self, chat_history: List[BaseMessage]) -> List[BaseMessage]:
        """
        ä¼šè©±å±¥æ­´ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°
        
        Args:
            chat_history: ä¼šè©±å±¥æ­´
            
        Returns:
            ãƒˆãƒªãƒŸãƒ³ã‚°ã•ã‚ŒãŸä¼šè©±å±¥æ­´
        """
        if len(chat_history) > self.max_history * 2:
            # æœ€æ–°ã®Nä»¶ã®ã¿ä¿æŒï¼ˆè³ªå•ã¨å›ç­”ã®ãƒšã‚¢ãªã®ã§ *2ï¼‰
            return chat_history[-(self.max_history * 2):]
        return chat_history
    
    def save_conversation(self, session_id: str, chat_history: List[BaseMessage]):
        """
        ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
            chat_history: ä¼šè©±å±¥æ­´
        """
        # å®Ÿè£…ã¯å¿…è¦ã«å¿œã˜ã¦
        pass


class ErrorHandler:
    """
    ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹
    LangChainé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã‚’é©åˆ‡ã«å‡¦ç†ã—ã¾ã™
    """
    
    @staticmethod
    def handle_llm_error(error: Exception) -> str:
        """
        LLMã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†
        
        Args:
            error: ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼
            
        Returns:
            ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        error_str = str(error).lower()
        
        # APIã‚­ãƒ¼é–¢é€£ã®ã‚¨ãƒ©ãƒ¼
        if "api" in error_str and ("key" in error_str or "auth" in error_str):
            return "APIã‚­ãƒ¼ã®è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼
        if "rate" in error_str or "quota" in error_str or "429" in error_str:
            return """âš ï¸ Google Gemini APIã®åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚

**ğŸ“Š ç¾çŠ¶:**
- Google Gemini APIç„¡æ–™æ ãŒæ¯æ¸‡ã—ã¦ã„ã¾ã™
- åˆ¶é™ã¯24æ™‚é–“å¾Œã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™

**âœ… å³æ™‚è§£æ±ºç­–ï¼ˆæ¨å¥¨ï¼‰:**
OpenAI APIã‚­ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã™ãã«åˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

**è¨­å®šæ–¹æ³•:**
1. Streamlit Cloudï¼ˆhttps://share.streamlit.ioï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹
2. ã‚¢ãƒ—ãƒªã®ã€Œâš™ï¸ Settingsã€â†’ã€ŒSecretsã€ã‚’é–‹ã
3. ä»¥ä¸‹ã‚’è¿½åŠ ã—ã¦ã€ŒSaveã€ã‚’ã‚¯ãƒªãƒƒã‚¯:
   ```
   OPENAI_API_KEY = "ã‚ãªãŸã®OpenAI APIã‚­ãƒ¼"
   ```

**â³ ä»£æ›¿ç­–:**
24æ™‚é–“å¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ï¼ˆGoogle Gemini APIã®åˆ¶é™ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ï¼‰

â€» OpenAI APIã‚­ãƒ¼ã«ã¤ã„ã¦ã¯ã€ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"""
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼
        if "timeout" in error_str:
            return "å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚‚ã†å°‘ã—çŸ­ã„è³ªå•ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚"
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
        if "network" in error_str or "connection" in error_str:
            return "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        
        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(error)}\nç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
_rate_limiter = None
_query_cache = None
_langchain_logger = None
_conversation_manager = None


def get_rate_limiter() -> RateLimiter:
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _rate_limiter
    if _rate_limiter is None:
        _rate_limiter = RateLimiter(max_requests=10, time_window=60)
    return _rate_limiter


def get_query_cache() -> QueryCache:
    """ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _query_cache
    if _query_cache is None:
        _query_cache = QueryCache()
    return _query_cache


def get_langchain_logger() -> LangChainLogger:
    """LangChainãƒ­ã‚¬ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _langchain_logger
    if _langchain_logger is None:
        _langchain_logger = LangChainLogger()
    return _langchain_logger


def get_conversation_manager() -> ConversationManager:
    """ä¼šè©±ç®¡ç†ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _conversation_manager
    if _conversation_manager is None:
        _conversation_manager = ConversationManager(max_history=10)
    return _conversation_manager

