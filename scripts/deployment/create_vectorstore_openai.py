"""
OpenAI APIã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’äº‹å‰ä½œæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
1. .envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®š
2. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ: python create_vectorstore_openai.py
3. vectorstore/ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã‚‹
4. GitHubã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹
"""

import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

import constants as ct
from initialize import load_data_sources, adjust_string

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«å¤‰æ›´
os.chdir(project_root)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

def create_vectorstore():
    """ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä½œæˆï¼ˆOpenAI APIä½¿ç”¨ï¼‰"""
    
    print("=" * 60)
    print("ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (OpenAI API)")
    print("=" * 60)
    print(f"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
    print("=" * 60)
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print("\nğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    docs_all = load_data_sources()
    print(f"âœ“ {len(docs_all)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–
    print("\nğŸ”„ ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ã—ã¦ã„ã¾ã™...")
    for doc in docs_all:
        doc.page_content = adjust_string(doc.page_content)
        for key in doc.metadata:
            doc.metadata[key] = adjust_string(doc.metadata[key])
    print("âœ“ ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    print("\nğŸ”„ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
    openai_api_key = os.getenv("OPENAI_API_KEY")
    
    if not openai_api_key:
        raise ValueError(
            "OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
            ".envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¨­å®šã—ã¦ãã ã•ã„:\n"
            'OPENAI_API_KEY="your-api-key-here"'
        )
    
    print(f"âœ“ APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆå…ˆé ­10æ–‡å­—: {openai_api_key[:10]}...ï¼‰")
    
    # OpenAI Embeddingsã‚’ä½¿ç”¨ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åˆ¶å¾¡ï¼‰
    embeddings = OpenAIEmbeddings(
        model=ct.EMBEDDING_MODEL_OPENAI,
        openai_api_key=openai_api_key,
        chunk_size=100  # 1å›ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã§å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆæ•°ã‚’åˆ¶é™
    )
    print("âœ“ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("  - ãƒãƒƒãƒã‚µã‚¤ã‚º: 100ãƒ†ã‚­ã‚¹ãƒˆ/ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾å¿œï¼‰")
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²
    print("\nğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²ã—ã¦ã„ã¾ã™...")
    text_splitter = CharacterTextSplitter(
        chunk_size=ct.CHUNK_SIZE,
        chunk_overlap=ct.CHUNK_OVERLAP,
        separator="\n"
    )
    splitted_docs = text_splitter.split_documents(docs_all)
    print(f"âœ“ {len(splitted_docs)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")
    
    # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ä½œæˆã¨ä¿å­˜
    print("\nğŸ”„ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ä½œæˆã—ã¦ã„ã¾ã™ï¼ˆã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰...")
    print("âš ï¸ ã“ã®å‡¦ç†ä¸­ã«OpenAI APIã®ã‚¯ã‚©ãƒ¼ã‚¿ã‚’æ¶ˆè²»ã—ã¾ã™ï¼ˆå°‘é¡ã®è²»ç”¨ï¼‰")
    print(f"ğŸ“Š å‡¦ç†: {len(splitted_docs)}ãƒãƒ£ãƒ³ã‚¯ Ã· 100 = ç´„{len(splitted_docs)//100 + 1}å›ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
    print("â³ äºˆæƒ³æ™‚é–“: 3ï½5åˆ†")
    
    # persist_directoryã‚’æŒ‡å®šã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
    db = Chroma.from_documents(
        documents=splitted_docs,
        embedding=embeddings,
        persist_directory="./vectorstore"  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
    )
    
    print("âœ“ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
    print(f"âœ“ ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ä¿å­˜ã—ã¾ã—ãŸ: ./vectorstore/")
    
    print("\n" + "=" * 60)
    print("âœ… å®Œäº†ï¼")
    print("=" * 60)
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. vectorstore/ ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª")
    print("2. ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§GitHubã«ãƒ—ãƒƒã‚·ãƒ¥:")
    print("   git add vectorstore/")
    print("   git add initialize.py")
    print("   git add create_vectorstore_openai.py")
    print('   git commit -m "Add pre-built vectorstore (OpenAI)"')
    print("   git push origin main")
    print("3. Streamlit Cloudã§ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•")
    print("\nğŸ’° ã‚³ã‚¹ãƒˆ:")
    print(f"   - {len(splitted_docs)}ãƒãƒ£ãƒ³ã‚¯ Ã— OpenAI Embedding API")
    print(f"   - æ¨å®šã‚³ã‚¹ãƒˆ: ç´„$0.02-0.05ï¼ˆ3-7å††ç¨‹åº¦ï¼‰")

if __name__ == "__main__":
    try:
        create_vectorstore()
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("\nè©³ç´°:")
        import traceback
        traceback.print_exc()



